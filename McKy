# https://github.com/sm86/McKinsey-Analytics-Hackathon/blob/master/DataPreparation.R

library(Rtsne)
library(reshape)
library(reshape2)
library(tidyr)
library(lubridate)
library(forecast)
library(TTR)
library(xgboost)
library(Metrics)

train <- read.csv("D:\\AA\\train_ZoGVYWq.csv",stringsAsFactors = F)
test <- read.csv("D:\\AA\\test_66516Ee.csv",stringsAsFactors = F)
submission <- read.csv("D:\\AA\\sample_submission_sLex1ul.csv",stringsAsFactors = F)
#train$DateTime <- ymd_hms(train$DateTime)

###### EXPLORATION
mean(train[,13])
0.93741
mean(train[is.na(train$application_underwriting_score),13])
mean(train$application_underwriting_score,na.rm=T)

###### NA fill
 (nrow(train)*mean(train$application_underwriting_score)+nrow(test)*mean(test$application_underwriting_score))/(nrow(train)+nrow(test))
#99.06567
train$application_underwriting_score[is.na(train$application_underwriting_score)] <- mean(train$application_underwriting_score, na.rm=T)
train$Count_3.6_months_late[is.na(train$Count_3.6_months_late)] <- 0
train$Count_6.12_months_late[is.na(train$Count_6.12_months_late)] <- 0
train$Count_more_than_12_months_late[is.na(train$Count_more_than_12_months_late)] <- 0
test$application_underwriting_score[is.na(test$application_underwriting_score)] <- mean(test$application_underwriting_score, na.rm=T)
test$Count_3.6_months_late[is.na(test$Count_3.6_months_late)] <- 0
test$Count_6.12_months_late[is.na(test$Count_6.12_months_late)] <- 0
test$Count_more_than_12_months_late[is.na(test$Count_more_than_12_months_late)] <- 0

#### FEATURES
train <- transform(train, sourcing_A = ifelse(sourcing_channel=='A', 1, 0))
train <- transform(train, sourcing_B = ifelse(sourcing_channel=='B', 1, 0))
train <- transform(train, sourcing_C = ifelse(sourcing_channel=='C', 1, 0))
train <- transform(train, sourcing_D = ifelse(sourcing_channel=='D', 1, 0))
train$sourcing_channel <- NULL
train <- transform(train, residence_area_type = ifelse(residence_area_type=='Urban', 1, 0))
test <- transform(test, sourcing_A = ifelse(sourcing_channel=='A', 1, 0))
test <- transform(test, sourcing_B = ifelse(sourcing_channel=='B', 1, 0))
test <- transform(test, sourcing_C = ifelse(sourcing_channel=='C', 1, 0))
test <- transform(test, sourcing_D = ifelse(sourcing_channel=='D', 1, 0))
test$sourcing_channel <- NULL
test <- transform(test, residence_area_type = ifelse(residence_area_type=='Urban', 1, 0))

  
######## XGB #########################################

test_target <- data.frame(renewal=train[c(50001:79583),c('renewal')])
test <- train[c(50001:79583),c('perc_premium_paid_by_cash_credit','age_in_days','Income',
  'Count_3.6_months_late','Count_6.12_months_late','Count_more_than_12_months_late','application_underwriting_score',
  'no_of_premiums_paid','residence_area_type','premium','sourcing_A','sourcing_B','sourcing_C','sourcing_D')]

train_target <- data.frame(renewal=train[c(1:50001),c('renewal')])
train <- train[c(1:50001),c('perc_premium_paid_by_cash_credit','age_in_days','Income',
  'Count_3.6_months_late','Count_6.12_months_late','Count_more_than_12_months_late','application_underwriting_score',
  'no_of_premiums_paid','residence_area_type','premium','sourcing_A','sourcing_B','sourcing_C','sourcing_D')]
  

## Making a small validation set to analyze progress
h <-sample(nrow(train_target),1000)
dval   <-xgb.DMatrix(data=data.matrix(train[h,]),label=train_target$target[h])
dtrain <-xgb.DMatrix(data=data.matrix(train[-h,]),label=train_target$target[-h])
cat("start training a model \n")
set.seed(3322)
xgb_watchlist <-list(val=dval,train=dtrain)
xgb_params <- list(  objective           = "reg:linear",  
                     booster = "gbtree",
                     eval_metric = "rmse",
                     eta                 = 0.1,  
                     max_depth           = 5,  
                     subsample           = 0.8,     
                     colsample_bytree    = 0.8,
                     min_child_weight = 1
)

xgb_model <- xgb.train(
  params              = xgb_params, 
  data                = dtrain, 
  nrounds             = 500,
  verbose             = 1,  #0 if full training set and no watchlist provided
  watchlist           = xgb_watchlist,
  print_every_n       = 20,
  maximize            = FALSE
)

###### train error

pred_xgb <- predict(xgb_model, data.matrix(train))
error <- data.frame(err=pred_xgb-train_target$target)
plot(error$err)

###### CV set perf

pred_xgb <- predict(xgb_model, data.matrix(test))
error <- data.frame(err=pred_xgb-test_target$target)
plot(error$err)
mean(error$err)
# -3.346118/-0.2223917/../-0.2966243
rmse(pred_xgb, test_target)
# 7.678513/3.496381/10.00209/3.577406

# Compute feature importance matrix
importance_matrix <- xgb.importance(colnames(train), model = xgb_model)
xgb.plot.importance(importance_matrix[1:10,])
